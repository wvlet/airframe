<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>airframe-parquet: Parquet Columnar File Reader and Writer · Airframe</title><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="generator" content="Docusaurus"/><meta name="description" content="airframe-parquet is a library for reading and writing for Scala objects using Parquet columnar data format."/><meta name="docsearch:language" content="en"/><meta property="og:title" content="airframe-parquet: Parquet Columnar File Reader and Writer · Airframe"/><meta property="og:type" content="website"/><meta property="og:url" content="https://wvlet.org/airframe/"/><meta property="og:description" content="airframe-parquet is a library for reading and writing for Scala objects using Parquet columnar data format."/><meta property="og:image" content="https://wvlet.org/airframe/img/poster.png"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://wvlet.org/airframe/img/poster.png"/><link rel="shortcut icon" href="/airframe/img/favicon.ico"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.css"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><link rel="alternate" type="application/atom+xml" href="https://wvlet.org/airframe/blog/atom.xml" title="Airframe Blog ATOM Feed"/><link rel="alternate" type="application/rss+xml" href="https://wvlet.org/airframe/blog/feed.xml" title="Airframe Blog RSS Feed"/><script>
              (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
              (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
              m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
              })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

              ga('create', 'UA-98364158-1', 'auto');
              ga('send', 'pageview');
            </script><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script src="/airframe/js/scrollSpy.js"></script><link rel="stylesheet" href="/airframe/css/main.css"/><script src="/airframe/js/codetabs.js"></script></head><body class="sideNavVisible separateOnPageNav"><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/airframe/"><img class="logo" src="/airframe/img/favicon.ico" alt="Airframe"/><h2 class="headerTitleWithLogo">Airframe</h2></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="/airframe/docs/" target="_self">Docs</a></li><li class=""><a href="/airframe/blog/" target="_self">Blog</a></li><li class=""><a href="/airframe/docs/release-notes" target="_self">Release Notes</a></li><li class=""><a href="https://github.com/wvlet/airframe/" target="_self">GitHub</a></li><li class="navSearchWrapper reactNavSearchWrapper"><input type="text" id="search_input_react" placeholder="Search" title="Search"/></li></ul></nav></div></header></div></div><div class="navPusher"><div class="docMainWrapper wrapper"><div class="docsNavContainer" id="docsNav"><nav class="toc"><div class="toggleNav"><section class="navWrapper wrapper"><div class="navBreadcrumb wrapper"><div class="navToggle" id="navToggler"><div class="hamburger-menu"><div class="line1"></div><div class="line2"></div><div class="line3"></div></div></div><h2><i>›</i><span>Utilities</span></h2><div class="tocToggler" id="tocToggler"><i class="icon-toc"></i></div></div><div class="navGroups"><div class="navGroup"><h3 class="navGroupCategoryTitle">Resources</h3><ul class=""><li class="navListItem"><a class="navItem" href="/airframe/docs/">Overview</a></li><li class="navListItem"><a class="navItem" href="/airframe/docs/airframe-walkthrough">Airframe Walkthrough: Building Applications Step by Step</a></li><li class="navListItem"><a class="navItem" href="/airframe/docs/articles">Articles</a></li><li class="navListItem"><a class="navItem" href="/airframe/docs/release-notes">Release Notes</a></li><li class="navListItem"><a class="navItem" href="/airframe/docs/logos">Logos</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle">Framework</h3><ul class=""><li class="navListItem"><a class="navItem" href="/airframe/docs/airframe-di">airframe-di: Dependency Injection</a></li><li class="navListItem"><a class="navItem" href="/airframe/docs/airframe-rpc">Airframe RPC</a></li><li class="navListItem"><a class="navItem" href="/airframe/docs/airframe-http">airframe-http: Creating REST Service</a></li><li class="navListItem"><a class="navItem" href="/airframe/docs/airframe-rx">airframe-rx: ReactiveX interface</a></li><li class="navListItem"><a class="navItem" href="/airframe/docs/airspec">AirSpec: Testing Framework</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle">Core Modules</h3><ul class=""><li class="navListItem"><a class="navItem" href="/airframe/docs/airframe-codec">airframe-codec: Schema-On-Read Object Serializer</a></li><li class="navListItem"><a class="navItem" href="/airframe/docs/airframe-config">airframe-config: Application Config Flow</a></li><li class="navListItem"><a class="navItem" href="/airframe/docs/airframe-control">airframe-control: Retry/Rate Control</a></li><li class="navListItem"><a class="navItem" href="/airframe/docs/airframe-log">airframe-log: Application Logger</a></li><li class="navListItem"><a class="navItem" href="/airframe/docs/airframe-metrics">airframe-metrics: Human-Friendly Measures for Time and Data Size</a></li><li class="navListItem"><a class="navItem" href="/airframe/docs/airframe-surface">airframe-surface: Object Shape Inspector</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle">Utilities</h3><ul class=""><li class="navListItem"><a class="navItem" href="/airframe/docs/airframe-benchmark">airframe-benchmark: JMH Benchmark</a></li><li class="navListItem"><a class="navItem" href="/airframe/docs/airframe-canvas">airframe-canvas: Off-Heap Memory Manager</a></li><li class="navListItem"><a class="navItem" href="/airframe/docs/airframe-fluentd">airframe-fluentd: Fluentd Logger</a></li><li class="navListItem"><a class="navItem" href="/airframe/docs/airframe-http-recorder">airframe-http-recorder: Web Request/Response Recorder</a></li><li class="navListItem"><a class="navItem" href="/airframe/docs/airframe-jdbc">airframe-jdbc: JDBC Connection Pool</a></li><li class="navListItem"><a class="navItem" href="/airframe/docs/airframe-jmx">airframe-jmx: JMX Application Monitor</a></li><li class="navListItem"><a class="navItem" href="/airframe/docs/airframe-json">airframe-json: Pure-Scala JSON Parser</a></li><li class="navListItem"><a class="navItem" href="/airframe/docs/airframe-launcher">airframe-launcher: Command-Line Program Launcher</a></li><li class="navListItem"><a class="navItem" href="/airframe/docs/airframe-msgpack">airframe-msgpack: Pure-Scala MessagePack Parser</a></li><li class="navListItem navListItemActive"><a class="navItem" href="/airframe/docs/airframe-parquet">airframe-parquet: Parquet Columnar File Reader and Writer</a></li><li class="navListItem"><a class="navItem" href="/airframe/docs/airframe-sql">airframe-sql: SQL Parser</a></li><li class="navListItem"><a class="navItem" href="/airframe/docs/airframe-ulid">airframe-ulid: ULID Generator</a></li></ul></div></div></section></div><script>
            var coll = document.getElementsByClassName('collapsible');
            var checkActiveCategory = true;
            for (var i = 0; i < coll.length; i++) {
              var links = coll[i].nextElementSibling.getElementsByTagName('*');
              if (checkActiveCategory){
                for (var j = 0; j < links.length; j++) {
                  if (links[j].classList.contains('navListItemActive')){
                    coll[i].nextElementSibling.classList.toggle('hide');
                    coll[i].childNodes[1].classList.toggle('rotate');
                    checkActiveCategory = false;
                    break;
                  }
                }
              }

              coll[i].addEventListener('click', function() {
                var arrow = this.childNodes[1];
                arrow.classList.toggle('rotate');
                var content = this.nextElementSibling;
                content.classList.toggle('hide');
              });
            }

            document.addEventListener('DOMContentLoaded', function() {
              createToggler('#navToggler', '#docsNav', 'docsSliderActive');
              createToggler('#tocToggler', 'body', 'tocActive');

              var headings = document.querySelector('.toc-headings');
              headings && headings.addEventListener('click', function(event) {
                var el = event.target;
                while(el !== headings){
                  if (el.tagName === 'A') {
                    document.body.classList.remove('tocActive');
                    break;
                  } else{
                    el = el.parentNode;
                  }
                }
              }, false);

              function createToggler(togglerSelector, targetSelector, className) {
                var toggler = document.querySelector(togglerSelector);
                var target = document.querySelector(targetSelector);

                if (!toggler) {
                  return;
                }

                toggler.onclick = function(event) {
                  event.preventDefault();

                  target.classList.toggle(className);
                };
              }
            });
        </script></nav></div><div class="container mainContainer docsContainer"><div class="wrapper"><div class="post"><header class="postHeader"><h1 id="__docusaurus" class="postHeaderTitle">airframe-parquet: Parquet Columnar File Reader and Writer</h1></header><article><div><span><p>airframe-parquet is a library for reading and writing for Scala objects using Parquet columnar data format.</p>
<h2><a class="anchor" aria-hidden="true" id="usage"></a><a href="#usage" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Usage</h2>
<p><a href="https://maven-badges.herokuapp.com/maven-central/org.wvlet.airframe/airframe-parquet_2.12/"><img src="https://maven-badges.herokuapp.com/maven-central/org.wvlet.airframe/airframe-parquet_2.12/badge.svg" alt="Maven Central"></a></p>
<pre><code class="hljs css language-scala">libraryDependencies ++= <span class="hljs-type">Seq</span>(
  <span class="hljs-string">"org.wvlet.airframe"</span> %% <span class="hljs-string">"airframe-parquet"</span> % <span class="hljs-string">"(version)"</span>
  <span class="hljs-comment">// Use your own hadoop version</span>
  <span class="hljs-string">"org.apache.hadoop"</span>  % <span class="hljs-string">"hadoop-client"</span>  % <span class="hljs-string">"3.4.0"</span>,
  <span class="hljs-comment">// [Optional] For supporting S3</span>
  <span class="hljs-string">"org.apache.hadoop"</span>  % <span class="hljs-string">"hadoop-aws"</span>  % <span class="hljs-string">"3.4.0"</span>,
  <span class="hljs-comment">// [Optional] For using custom AWS credential provider</span>
  <span class="hljs-string">"software.amazon.awssdk"</span> % <span class="hljs-string">"auth"</span> % <span class="hljs-string">"2.25.13"</span>
)
</code></pre>
<pre><code class="hljs css language-scala"><span class="hljs-keyword">import</span> wvlet.airframe.parquet.<span class="hljs-type">Parquet</span>

<span class="hljs-keyword">case</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MyEntry</span>(<span class="hljs-params">id: <span class="hljs-type">Int</span>, name:<span class="hljs-type">String</span></span>)</span>

<span class="hljs-comment">// Writing objects to file</span>
<span class="hljs-keyword">val</span> writer = <span class="hljs-type">Parquet</span>.newWriter[<span class="hljs-type">MyEntry</span>](path = <span class="hljs-string">"data.parquet"</span>)
writer.write(<span class="hljs-type">MyEntry</span>(<span class="hljs-number">1</span>, <span class="hljs-string">"leo"</span>))
writer.write(<span class="hljs-type">MyEntry</span>(<span class="hljs-number">2</span>, <span class="hljs-string">"yui"</span>))
<span class="hljs-comment">// Ensure writing entries to the file</span>
writer.close()

<span class="hljs-comment">// Reading Parquet data as objects</span>
<span class="hljs-keyword">val</span> reader = <span class="hljs-type">Parquet</span>.newReader[<span class="hljs-type">MyEntry</span>](path = <span class="hljs-string">"data.parquet"</span>)
<span class="hljs-keyword">val</span> e1 = reader.read() <span class="hljs-comment">// MyEntry(1,"leo")</span>
<span class="hljs-keyword">val</span> e2 = reader.read() <span class="hljs-comment">// MyEntry(2,"yui")</span>
reader.read() <span class="hljs-comment">// null</span>
reader.close()

<span class="hljs-comment">// Reading records as Map[String, Any]</span>
<span class="hljs-keyword">val</span> mapReader = <span class="hljs-type">Parquet</span>.newReader[<span class="hljs-type">Map</span>[<span class="hljs-type">String</span>, <span class="hljs-type">Any</span>]](path = <span class="hljs-string">"data.parquet"</span>)
<span class="hljs-keyword">val</span> m1 = mapReader.read() <span class="hljs-comment">// Map("id"-&gt;1, "name" -&gt; "leo")</span>
<span class="hljs-keyword">val</span> m2 = mapReader.read() <span class="hljs-comment">// Map("id"-&gt;2, "name" -&gt; "yui")</span>
mapReader.read() <span class="hljs-comment">// null</span>
mapReader.close()

<span class="hljs-comment">// Reading records as Json</span>
<span class="hljs-keyword">import</span> wvlet.airframe.json.<span class="hljs-type">Json</span>
<span class="hljs-keyword">val</span> jsonReader = <span class="hljs-type">Parquet</span>.newReader[<span class="hljs-type">Json</span>](path = <span class="hljs-string">"data.parquet"</span>)
<span class="hljs-keyword">val</span> j1 = jsonReader.read() <span class="hljs-comment">// {"id":1,"name":"leo"}</span>
<span class="hljs-keyword">val</span> j2 = jsonReader.read() <span class="hljs-comment">// {"id":2,"name":"yui"} </span>
jsonReader.read() <span class="hljs-comment">// null</span>
jsonReader.close()

<span class="hljs-comment">// Writing dynamically generated records</span>
<span class="hljs-keyword">import</span> org.apache.parquet.schema._
<span class="hljs-comment">// Create a Parquet schema</span>
<span class="hljs-keyword">val</span> schema = <span class="hljs-keyword">new</span> <span class="hljs-type">MessageType</span>(
  <span class="hljs-string">"MyEntry"</span>,
  <span class="hljs-type">Types</span>.required(<span class="hljs-type">PrimitiveTypeName</span>.<span class="hljs-type">INT32</span>).named(<span class="hljs-string">"id"</span>),
  <span class="hljs-type">Types</span>.optional(<span class="hljs-type">PrimitiveTypeName</span>.<span class="hljs-type">BINARY</span>).as(stringType).named(<span class="hljs-string">"name"</span>)
)
<span class="hljs-comment">// Create a record writer for the given schema</span>
<span class="hljs-keyword">val</span> recordWriter = <span class="hljs-type">Parquet</span>.newRecordWriter(path = <span class="hljs-string">"record.parquet"</span>, schema = schema)
<span class="hljs-comment">// Write a record using Map (column name -&gt; value)</span>
recordWriter.write(<span class="hljs-type">Map</span>(<span class="hljs-string">"id"</span> -&gt; <span class="hljs-number">1</span>, <span class="hljs-string">"name"</span> -&gt; <span class="hljs-string">"leo"</span>))
<span class="hljs-comment">// Write a record using JSON object</span>
recordWriter.write(<span class="hljs-string">""</span><span class="hljs-string">"{"</span><span class="hljs-string">id":2, "</span><span class="hljs-string">name":"</span><span class="hljs-string">yui"}"</span><span class="hljs-string">""</span>)
<span class="hljs-comment">// Write a record using Array</span>
recordWriter.write(<span class="hljs-type">Seq</span>(<span class="hljs-number">3</span>, <span class="hljs-string">"aina"</span>))
<span class="hljs-comment">// Write a record using JSON array</span>
recordWriter.write(<span class="hljs-string">""</span><span class="hljs-string">"[4, "</span><span class="hljs-string">xxx"]"</span><span class="hljs-string">""</span>)
recordWriter.close()


<span class="hljs-comment">// In case you need to write dynamic recoreds containing case classes,</span>
<span class="hljs-comment">// register the Surfaces of these classes</span>
<span class="hljs-keyword">case</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Nested</span>(<span class="hljs-params">id:<span class="hljs-type">Int</span>, entry:<span class="hljs-type">MyEntry</span></span>)</span>
<span class="hljs-keyword">val</span> nestedRecordWriter = <span class="hljs-type">Parquet</span>.newRecordWriter(
  path = <span class="hljs-string">"nested.parquet"</span>,
  <span class="hljs-comment">// You can build a Parquet schema matching to Surface</span>
  schema = <span class="hljs-type">Parquet</span>.toParquetSchema(<span class="hljs-type">Surface</span>.of[<span class="hljs-type">Nested</span>]),
  knownSurfaces = <span class="hljs-type">Seq</span>(<span class="hljs-type">Surface</span>.of[<span class="hljs-type">MyEntry</span>]) <span class="hljs-comment">// required to serialize MyEntry</span>
)

<span class="hljs-comment">// Write dynamic records</span>
nestedRecordWriter.write(<span class="hljs-type">Map</span>(<span class="hljs-string">"id"</span> -&gt; <span class="hljs-number">1</span>, <span class="hljs-string">"entry"</span> -&gt; <span class="hljs-type">MyEntry</span>(<span class="hljs-number">1</span>, <span class="hljs-string">"yyy"</span>))
nestedRecordWriter.write(<span class="hljs-type">Map</span>(<span class="hljs-string">"id"</span> -&gt; <span class="hljs-number">2</span>, <span class="hljs-string">"entry"</span> -&gt; <span class="hljs-type">MyEntry</span>(<span class="hljs-number">2</span>, <span class="hljs-string">"zzz"</span>))
nestedRecordWriter.close()
</code></pre>
<h3><a class="anchor" aria-hidden="true" id="using-with-aws-s3"></a><a href="#using-with-aws-s3" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Using with AWS S3</h3>
<p>airframe-parquet uses HadoopFileSystem for reading data from S3.
hadoopConf needs to be configured for AWS authentication.</p>
<pre><code class="hljs css language-scala"><span class="hljs-keyword">import</span> org.apache.hadoop.conf.<span class="hljs-type">Configuration</span>

<span class="hljs-keyword">val</span> conf = <span class="hljs-keyword">new</span> <span class="hljs-type">Configuration</span>()
<span class="hljs-comment">// Option 1: Using AWS keys</span>
conf.set(<span class="hljs-string">"fs.s3a.access.key"</span>, <span class="hljs-string">"..."</span>)
conf.set(<span class="hljs-string">"fs.s3a.secret.key"</span>, <span class="hljs-string">"..."</span>)

<span class="hljs-comment">// Option 2: Using a custom AWS credential provider implementing com.amazonaws.auth.AWSCredentialsProvider</span>
conf.set(<span class="hljs-string">"fs.s3a.aws.credentials.provider"</span>, <span class="hljs-string">"com.amazonaws.auth.DefaultAWSCredentialsProviderChain"</span>)

<span class="hljs-comment">// Use s3a:// prefix to specify an S3 path, and pass hadoopConf</span>
<span class="hljs-type">Parquet</span>.newReader[<span class="hljs-type">MyEntry</span>](path = <span class="hljs-string">"s3a://my-bucket/data.parquet"</span>, hadoopConf = conf)
</code></pre>
<p>For other configuration parameters, see also <a href="https://hadoop.apache.org/docs/stable/hadoop-aws/tools/hadoop-aws/index.html">hadoop-aws</a> documentation.</p>
<h2><a class="anchor" aria-hidden="true" id="querying-parquet-with-a-simple-sql"></a><a href="#querying-parquet-with-a-simple-sql" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Querying Parquet with A Simple SQL</h2>
<p>To apply column projection and predicate filtering, you can use SQL statements. The syntax of SQL is <code>select column1, column2, ... from _ where (column condition)</code>. The input table name must be just <code>_</code> (underscore). The where clause condition supports only a limited set of predicates, <code>=</code>, <code>!=</code>, <code>&lt;</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&gt;=</code>, <code>BETWEEN</code>, <code>OR</code>, <code>AND</code>, <code>IS NULL</code>, <code>IS NOT NULL</code>, etc., where the left operator is a column name.</p>
<p>Projecting columns:</p>
<pre><code class="hljs css language-scala"><span class="hljs-comment">// Selecting a subset of columns with SQL</span>
<span class="hljs-keyword">val</span> reader = <span class="hljs-type">Parquet</span>.query[<span class="hljs-type">Json</span>](path = <span class="hljs-string">"data.parquet"</span>, sql = <span class="hljs-string">"select id from _"</span>)
reader.read() <span class="hljs-comment">// {"id":1}</span>
reader.read() <span class="hljs-comment">// {"id":2}</span>
reader.read() <span class="hljs-comment">// null</span>
</code></pre>
<p>Filtering records:</p>
<pre><code class="hljs css language-scala"><span class="hljs-comment">// Selecting a subset of columns with SQL</span>
<span class="hljs-keyword">val</span> reader = <span class="hljs-type">Parquet</span>.query[<span class="hljs-type">Json</span>](path = <span class="hljs-string">"data.parquet"</span>, sql = <span class="hljs-string">"select * from _ where id = 2"</span>)
reader.read() <span class="hljs-comment">// {"id":2}</span>
reader.read() <span class="hljs-comment">// null</span>
</code></pre>
<h2><a class="anchor" aria-hidden="true" id="column-projection-with-model-classes"></a><a href="#column-projection-with-model-classes" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Column Projection with Model Classes</h2>
<p>If you need to read only a subset of columns, use a model class that has fewer parameters from the original model class. The Parquet reader will access only to the column blocks of the specified column in the model class parameters:</p>
<pre><code class="hljs css language-scala"><span class="hljs-keyword">case</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MyRecord</span>(<span class="hljs-params">p1:<span class="hljs-type">Int</span>, p2: <span class="hljs-type">String</span>, p3:<span class="hljs-type">Boolean</span></span>)</span>

<span class="hljs-keyword">val</span> writer = <span class="hljs-type">Parquet</span>.newWriter[<span class="hljs-type">MyRecord</span>](path = <span class="hljs-string">"record.parquet"</span>)
writer.write(...)
writer.close()

<span class="hljs-keyword">case</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MyRecordProjection</span>(<span class="hljs-params">p1:<span class="hljs-type">Int</span>, p3:<span class="hljs-type">Boolean</span></span>)</span>
<span class="hljs-keyword">val</span> reader = <span class="hljs-type">Parquet</span>.newReader[<span class="hljs-type">MyRecordProjection</span>](path = <span class="hljs-string">"record.parquet"</span>)

<span class="hljs-comment">// Only p1 and p3 columns will be read from the Parquet file</span>
reader.read() <span class="hljs-comment">// MyRecordProjection(p1, p3)</span>
reader.close()
</code></pre>
<h2><a class="anchor" aria-hidden="true" id="applying-row-group-filter-with-parquet-filterapi"></a><a href="#applying-row-group-filter-with-parquet-filterapi" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Applying Row Group Filter with Parquet FilterApi</h2>
<p>Parquet can skip reading records by using row group filters.
You can use <a href="https://github.com/justcodeforfun/parquet-mr/blob/main/parquet-column/src/main/java/org/apache/parquet/filter2/predicate/FilterApi.java">FilterAPI of parquet-mr</a> to build such a filter:</p>
<pre><code class="hljs css language-scala"><span class="hljs-keyword">import</span> org.apache.parquet.filter2.compat.<span class="hljs-type">FilterCompat</span>
<span class="hljs-keyword">import</span> org.apache.parquet.filter2.predicate.<span class="hljs-type">FilterApi</span>

<span class="hljs-comment">// Describing filter condition using parquet-mr FilterApi</span>
<span class="hljs-keyword">val</span> filter = <span class="hljs-type">FilterCompat</span>.get(
  <span class="hljs-type">FilterApi</span>.eq(
    <span class="hljs-type">FilterApi</span>.intColumn(<span class="hljs-string">"id"</span>),
    <span class="hljs-type">Integer</span>.valueOf(<span class="hljs-number">100</span>) <span class="hljs-comment">// Need to use Java primitive values</span>
  )
)

<span class="hljs-keyword">val</span> reader = <span class="hljs-type">Parquet</span>.newReader[<span class="hljs-type">MyEntry</span>](
  path = <span class="hljs-string">"data.parquet"</span>,
  <span class="hljs-comment">// Set your filter here</span>
  config = _.withFilter(filter)
)
</code></pre>
<h2><a class="anchor" aria-hidden="true" id="read-column-statistics"></a><a href="#read-column-statistics" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Read Column Statistics</h2>
<pre><code class="hljs css language-scala"><span class="hljs-comment">// Read Parquet metadat to get column statistics</span>
<span class="hljs-keyword">val</span> stats: <span class="hljs-type">Map</span>[<span class="hljs-type">String</span>, <span class="hljs-type">ColumnStatistics</span>] = <span class="hljs-type">Parquet</span>.readStatistics(<span class="hljs-string">"data.parquet"</span>)
<span class="hljs-comment">// Map(id -&gt; ColumnStatistics(numNulls = Some(0), uncompressedSize = Some(..), .., minValue = Some(1), maxValue = Some(2)), ... )</span>
</code></pre>
</span></div></article></div><div class="docs-prevnext"><a class="docs-prev button" href="/airframe/docs/airframe-msgpack"><span class="arrow-prev">← </span><span class="function-name-prevnext">airframe-msgpack: Pure-Scala MessagePack Parser</span></a><a class="docs-next button" href="/airframe/docs/airframe-sql"><span>airframe-sql: SQL Parser</span><span class="arrow-next"> →</span></a></div></div></div><nav class="onPageNav"><ul class="toc-headings"><li><a href="#usage">Usage</a><ul class="toc-headings"><li><a href="#using-with-aws-s3">Using with AWS S3</a></li></ul></li><li><a href="#querying-parquet-with-a-simple-sql">Querying Parquet with A Simple SQL</a></li><li><a href="#column-projection-with-model-classes">Column Projection with Model Classes</a></li><li><a href="#applying-row-group-filter-with-parquet-filterapi">Applying Row Group Filter with Parquet FilterApi</a></li><li><a href="#read-column-statistics">Read Column Statistics</a></li></ul></nav></div><footer class="nav-footer" id="footer"><section class="sitemap"><a href="/airframe/" class="nav-home"><img src="/airframe/img/favicon.ico" alt="Airframe" width="66" height="66"/></a><div><h5>Docs</h5><a href="/airframe/docs/en/index.html">Documentation</a></div><div><h5>Community</h5><a href="https://gitter.im/wvlet/airframe">Gitter Chat</a></div><div><h5>More</h5><a href="https://github.com/wvlet/airframe/">GitHub</a><a class="github-button" href="https://github.com/wvlet/airframe" data-icon="octicon-star" data-count-href="/wvlet/airframe/stargazers" data-show-count="true" data-count-aria-label="# stargazers on GitHub" aria-label="Star this project on GitHub">Star</a></div></section><a href="https://wvlet.org/airframe/" target="_blank" rel="noreferrer noopener" class="fbOpenSource"><img src="/airframe/img/logos/airframe-badge-dark.png" alt="airframe logo"/></a><section class="copyright">Copyright © 2025 wvlet.org</section></footer></div><script type="text/javascript" src="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.js"></script><script>window.fbAsyncInit = function() {FB.init({appId:'3112325918843547',xfbml:true,version:'v2.7'});};(function(d, s, id){var js, fjs = d.getElementsByTagName(s)[0];if (d.getElementById(id)) {return;}js = d.createElement(s); js.id = id;js.src = '//connect.facebook.net/en_US/sdk.js';fjs.parentNode.insertBefore(js, fjs);}(document, 'script','facebook-jssdk'));
                </script><script>window.twttr=(function(d,s, id){var js,fjs=d.getElementsByTagName(s)[0],t=window.twttr||{};if(d.getElementById(id))return t;js=d.createElement(s);js.id=id;js.src='https://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js, fjs);t._e = [];t.ready = function(f) {t._e.push(f);};return t;}(document, 'script', 'twitter-wjs'));</script><script>
                document.addEventListener('keyup', function(e) {
                  if (e.target !== document.body) {
                    return;
                  }
                  // keyCode for '/' (slash)
                  if (e.keyCode === 191) {
                    const search = document.getElementById('search_input_react');
                    search && search.focus();
                  }
                });
              </script><script>
              var search = docsearch({
                
                apiKey: '71b7e81be03c97dcd37b7a0efc8d6b76',
                indexName: 'airframe',
                inputSelector: '#search_input_react'
              });
            </script></body></html>